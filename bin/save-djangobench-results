#!/usr/bin/env python

from optparse import OptionParser
import json
import os
import logging
import sys

from speedcenter.client import save_to_speedcenter


def save_result(data, options):
    common_params = {"url":options.url, "project":options.project, 
                        "environment": options.environment,
                        "executable": options.executable,
                        "benchmark": data['name']}
    
    # Codespeed assumes that you record a baseline once and then compare to
    # the save results; djangobench assumes that you do the comparison each
    # time. Rather than recording
    
    result = data['result']
    
    ctl_params = common_params.copy()
    if options.save_control:
        if 'avg_base' in result:
            ctl_params.update({
                "result_value": result['avg_base'],
                "min": result['min_base'],
                "stddev": result['std_base'],
            })
        else:
            ctl_params.update({'result_value': result['base_time']})
        
        save_to_speedcenter(commitid=options.control_commit_id,
                            **ctl_params)

    exp_params = common_params.copy()
    if 'avg_changed' in result:
        exp_params.update({
            "result_value": result['avg_changed'],
            "min": result['min_changed'],
            "stddev": result['std_changed'],
        })
    else:
        exp_params.update({'result_value': result['changed_time']})

    save_to_speedcenter(commitid=options.commit_id,
                        **exp_params)


def main():
    logging.basicConfig(format="%(asctime)s [%(levelname)s]: %(message)s",
                        level=logging.INFO)

    parser = OptionParser()
    parser.add_option("--commit-id", help="Commit ID of the experimental version")
    parser.add_option("--control-commit-id", help="Commit ID of the control version")
    parser.add_option("--environment", help="Use a custom Codespeed environment")
    parser.add_option("--save-control", action="store_true", default=False, 
                        help="Control whether we save the control values as well "
                                "as the experimental values")
    parser.add_option("--executable")
    parser.add_option("--project", default="Django")
    parser.add_option("--url", help="URL of your Codespeed server (e.g. http://codespeed.example.org)")

    (options, args) = parser.parse_args()

    if len(args) != 1:
        parser.error("You must provide the path to djangobench's JSON results")

    required = ('url', 'environment', 'project', 'commit_id', 'executable')

    if not all(getattr(options, i) for i in required):
        parser.error("The following parameters must be provided:\n\t%s" % "\n\t".join(
            "--%s".replace("_", "-") % i for i in required))
        
    if options.save_control and not options.control_commit_id:
        parser.error("You must provide the control commit ID when saving control results")

    result_dir = args[0]
    if not os.path.exists(result_dir):
        parser.error("%s does not exist" % result_dir)
    
    for f in os.listdir(result_dir):
        if not f.endswith("json"):
            continue

        logging.info("Saving %s", f)

        data = json.load(file(os.path.join(result_dir, f), "rb"))

        try:
            save_result(data, options)
        except StandardError, e:
            logging.warning("Error saving %s: %s", f, e, exc_info=True)
            sys.exit(1)
            
if __name__ == "__main__":
    main()